{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# PARSING etherscan.io\n",
    "\n",
    "I made an attempt to parse more full information about user's transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Modules to reload:\n",
      "all-except-skipped\n",
      "\n",
      "Modules to skip:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from user_agent import generate_user_agent\n",
    "from application.load_transaction_data import load_ether_data, load_token_data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "transactions_df = load_ether_data()\\\n",
    "    .query(\"Status != 'Error(0)'\")\n",
    "token_df = load_token_data()\n",
    "\n",
    "transactions_transfers_df = pd.read_pickle(\"data/transactions_transfers_df\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 1110/7418 [19:24<2:01:13,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not convert string to float: '1 wei From Wrapped'\n",
      "Error on 0x90c67a86473a56f543d0984e569e60f4b70ea85a623342c822bc0b4d5821ce7e\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 5398/7418 [2:30:23<1:22:55,  2.46s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not convert string to float: '90 wei From SushiSwap: Router To  0x99fd1378ca799ed6772fe7bcdc9b30b389518962'\n",
      "Error on 0x428c9d824d6aa0c2599ee48be07592efd37c5eac7ea66a8bce9678f537dbdd3d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7418/7418 [4:00:43<00:00,  1.95s/it]  \n"
     ]
    }
   ],
   "source": [
    "def export_transfer_list(transfer: str):\n",
    "    # try:\n",
    "    #     amount = re.findall(r\"(\\d+\\.\\d+|\\d+\\,\\d+)\", transfer)[0]\n",
    "    # except IndexError:\n",
    "    #     amount = re.findall(r\"\\d+\", transfer)[0]\n",
    "    amount = float(transfer.split(\"TRANSFER\")[1].split(\"Ether\")[0].strip(\" \").replace(\",\", \"\"))\n",
    "    from_ = re.findall(r\"From (.*?) To\", transfer)[0]\n",
    "    to_ = transfer.split(\"  \")[-1]\n",
    "    return amount, from_, to_\n",
    "\n",
    "\n",
    "def extract_token_info(token_url):\n",
    "    result_dict = {}\n",
    "\n",
    "    # Parse from and to\n",
    "    try:\n",
    "        result_dict['from'] =  token_url.find(\"span\", class_='hash-tag text-truncate hash-tag-custom-from tooltip-address').text\n",
    "    except Exception as e:\n",
    "        result_dict['from'] = e\n",
    "    try:\n",
    "        result_dict['to'] = token_url.find(\"span\", class_='hash-tag text-truncate hash-tag-custom-to tooltip-address').text\n",
    "    except Exception as e:\n",
    "        result_dict['to'] = e\n",
    "\n",
    "    # Parse USD value. Check, where or not does USD value exist on this page?\n",
    "    try:\n",
    "        token1_usd = re.findall(r\"\\(\\$.*?\\)\", str(token_url))[0]\n",
    "        token1_usd = token1_usd.strip(\"()\").replace(\" (\", \"\").replace(\"$\", \"\")\n",
    "        result_dict['usd'] = float(token1_usd.replace(\",\", \"_\"))\n",
    "        result_dict['amount'] = token_url.find(\"span\", 'data-toggle'=='tooltip').text\n",
    "        result_dict['amount'] = float(result_dict['amount'].replace(\",\", \"\"))\n",
    "    except (AttributeError, IndexError) as e:\n",
    "        result_dict['usd'] = 'empty'\n",
    "        result_dict['amount'] = token_url.find_all(\"span\", class_='mr-1')[-1].text\n",
    "        result_dict['amount'] = float(result_dict['amount'].replace(\",\", \"\"))\n",
    "\n",
    "    # Parse token hash in order to parse full info later\n",
    "    try:\n",
    "        result_dict['token_hash'] = token_url.find(\"a\").get(\"href\").split(\"?\")[0].split(\"/\")[2]\n",
    "    except Exception as e:\n",
    "        result_dict['token_hash'] = e\n",
    "    return result_dict\n",
    "\n",
    "def extract_tokens_info(transaction_hash):\n",
    "    req = requests.get(f\"https://etherscan.io/tx/{transaction_hash}\",\n",
    "                   headers={\"User-Agent\": generate_user_agent()})\n",
    "    content = req.content\n",
    "    soup = BeautifulSoup(content)\n",
    "    tokens_df = []\n",
    "    bad_tokens = []\n",
    "    errors = []\n",
    "    all_tokens = soup.find_all(\"li\", class_='media align-items-baseline mb-2')\n",
    "    for index, tokens in enumerate(all_tokens):\n",
    "        try:\n",
    "            tokens_df.append(\n",
    "                pd.DataFrame.from_dict(extract_token_info(all_tokens[index]), orient='index').T\n",
    "            )\n",
    "        except Exception as e:\n",
    "            bad_tokens.append(index)\n",
    "            errors.append(e)\n",
    "    try:\n",
    "\n",
    "        tokens_df = pd.concat(tokens_df)\n",
    "    except ValueError:\n",
    "        tokens_df = pd.DataFrame(data=[transaction_hash], columns=['Txhash'])\n",
    "\n",
    "    tokens_df.index = np.arange(tokens_df.shape[0])\n",
    "    # TRANSFER parsing\n",
    "    transfer_text_list = []\n",
    "    transfers = soup.find_all(\"li\", class_='media align-items-baseline')\n",
    "    if len(transfers) > 0:\n",
    "        for transf in transfers:\n",
    "            transfer_text_list.append(transf.text.replace(\"\\xa0\", \"\"))\n",
    "\n",
    "        transfer_df = pd.DataFrame(list(map(export_transfer_list, transfer_text_list)), columns=['transfer_amount', 'transfer_from', 'transfer_to'])\n",
    "        tokens_df = pd.concat([tokens_df, transfer_df], axis=1)\n",
    "\n",
    "    tokens_df['Txhash'] = transaction_hash\n",
    "    return tokens_df\n",
    "\n",
    "all_tokens_df = []\n",
    "transactions_list = set(transactions_df['Txhash'])\n",
    "for tx_hash in tqdm(transactions_list):\n",
    "    try:\n",
    "        time.sleep(random.uniform(0, 1))\n",
    "        all_tokens_df.append(extract_tokens_info(tx_hash))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f\"Error on {tx_hash}\")\n",
    "    pd.concat(all_tokens_df).to_pickle(\"transactions_transfers_df\")\n",
    "# extract_tokens_info(\"0xdf08f1b6048a3c151737d797c5a5da5892cff66dfdfda319d4a260f358196c4b\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Parsing token hash"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "0    42\n1    42\n0    42\n1    42\n2    42\n     ..\n0    42\n1    42\n2    42\n3    42\n4    42\nName: token_hash, Length: 15740, dtype: int64"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions_transfers_df['token_hash'].dropna().map(len)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 245/245 [03:34<00:00,  1.14it/s]\n"
     ]
    }
   ],
   "source": [
    "all_token_hash = set(transactions_transfers_df['token_hash'].dropna())\n",
    "def parsing_tokens(token_hash):\n",
    "    token_dict = {}\n",
    "    token_dict['token_hash'] = token_hash\n",
    "    req = requests.get(f\"https://etherscan.io/token/{token_hash}\",\n",
    "                   headers={\"User-Agent\": generate_user_agent()})\n",
    "    content = req.content\n",
    "    soup = BeautifulSoup(content)\n",
    "    try:\n",
    "        token_dict['token_short_name'] = soup.find(\"span\", class_='text-secondary small').text\n",
    "    except Exception as e:\n",
    "        token_dict['token_short_name'] = e\n",
    "    try:\n",
    "        token_dict['token_long_name'] = soup.find(\"a\", class_='mb-1 mb-sm-0 u-label u-label--xs u-label--info').text\n",
    "    except Exception as e:\n",
    "        token_dict['token_long_name'] = e\n",
    "    return token_dict\n",
    "\n",
    "token_names_df = []\n",
    "for token in tqdm(all_token_hash):\n",
    "    time.sleep(random.uniform(0, 1))\n",
    "    try:\n",
    "        token_names_df.append(\n",
    "                pd.DataFrame.from_dict(parsing_tokens(token), orient='index').T)\n",
    "    except Exception as e:\n",
    "        token_names_df.append(pd.DataFrame(data=[token], columns=['Txhash']))\n",
    "token_names_df = pd.concat(token_names_df)\n",
    "token_names_df.to_pickle(\"data/token_hash_name\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "                                    token_hash         token_short_name  \\\n0   0xc7fd8dcee4697ceef5a2fd4608a7bd6a94c77480               Cream CRV    \n0   0x8cc94ccd0f3841a468184aca3cc478d2148e1757  Curve mUSD Pool yVault    \n0   0xc11b1268c1a384e55c48c2391d8d480264a3a7f4     Compound Wrapped BTC   \n0   0x3041cbd36888becc7bbcbc0045e3b1f144466f5f    Uniswap USDC/USDT LP    \n0   0x44fbebd2f576670a6c33f6fc0b00aa8c5753b322          Cream USD Coin    \n..                                         ...                      ...   \n0   0x998ceb152a42a3eac1f555b1e911642bebf00fad         FARM_cDAI+cUSDC    \n0   0x89ab32156e46f46d02ade3fecbe5fc4243b9aaed           pNetwork Token   \n0   0x8e595470ed749b85c6f7669de83eae304c2ec68f     Yearn Dai Stablecoin   \n0   0x10dd17ecfc86101eab956e0a443cab3e9c62d9b4     Balancer Pool Token    \n0   0xf650c3d88d12db855b8bf7d11be6c55a4e07dcc9            Compound USDT   \n\n                              token_long_name  \n0                               Cream.Finance  \n0   'NoneType' object has no attribute 'text'  \n0                                   Compound   \n0   'NoneType' object has no attribute 'text'  \n0                               Cream.Finance  \n..                                        ...  \n0   'NoneType' object has no attribute 'text'  \n0   'NoneType' object has no attribute 'text'  \n0                               Cream.Finance  \n0   'NoneType' object has no attribute 'text'  \n0                                   Compound   \n\n[245 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>token_hash</th>\n      <th>token_short_name</th>\n      <th>token_long_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0xc7fd8dcee4697ceef5a2fd4608a7bd6a94c77480</td>\n      <td>Cream CRV</td>\n      <td>Cream.Finance</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0x8cc94ccd0f3841a468184aca3cc478d2148e1757</td>\n      <td>Curve mUSD Pool yVault</td>\n      <td>'NoneType' object has no attribute 'text'</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0xc11b1268c1a384e55c48c2391d8d480264a3a7f4</td>\n      <td>Compound Wrapped BTC</td>\n      <td>Compound</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0x3041cbd36888becc7bbcbc0045e3b1f144466f5f</td>\n      <td>Uniswap USDC/USDT LP</td>\n      <td>'NoneType' object has no attribute 'text'</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0x44fbebd2f576670a6c33f6fc0b00aa8c5753b322</td>\n      <td>Cream USD Coin</td>\n      <td>Cream.Finance</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0x998ceb152a42a3eac1f555b1e911642bebf00fad</td>\n      <td>FARM_cDAI+cUSDC</td>\n      <td>'NoneType' object has no attribute 'text'</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0x89ab32156e46f46d02ade3fecbe5fc4243b9aaed</td>\n      <td>pNetwork Token</td>\n      <td>'NoneType' object has no attribute 'text'</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0x8e595470ed749b85c6f7669de83eae304c2ec68f</td>\n      <td>Yearn Dai Stablecoin</td>\n      <td>Cream.Finance</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0x10dd17ecfc86101eab956e0a443cab3e9c62d9b4</td>\n      <td>Balancer Pool Token</td>\n      <td>'NoneType' object has no attribute 'text'</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0xf650c3d88d12db855b8bf7d11be6c55a4e07dcc9</td>\n      <td>Compound USDT</td>\n      <td>Compound</td>\n    </tr>\n  </tbody>\n</table>\n<p>245 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_names_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}